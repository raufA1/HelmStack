# ğŸ—ï¸ HelmStack Architecture

## System Overview

HelmStack is built around a clean separation of concerns with pluggable components:

```
helmstack/
â”œâ”€â”€ ğŸ“„ Core Config
â”‚   â”œâ”€â”€ Makefile              # Command orchestration
â”‚   â”œâ”€â”€ .pre-commit-config.yaml
â”‚   â””â”€â”€ .github/workflows/    # CI/CD automation
â”‚
â”œâ”€â”€ ğŸ”§ Scripts & Logic
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ analyzers/        # Pluggable document analyzers
â”‚   â”‚   â”œâ”€â”€ *.sh             # Bash workflow scripts
â”‚   â”‚   â””â”€â”€ *.py             # Python processing tools
â”‚   â”‚
â”œâ”€â”€ ğŸ“ Workspace (All Working Files)
â”‚   â”œâ”€â”€ incoming/             # Input documents
â”‚   â”œâ”€â”€ processed/            # Archived/processed docs
â”‚   â”œâ”€â”€ plans/               # Generated plans & status
â”‚   â””â”€â”€ research/            # HITL research findings
â”‚
â”œâ”€â”€ ğŸ§  Memory System
â”‚   â”œâ”€â”€ memory/
â”‚   â”‚   â”œâ”€â”€ MEMORY.md         # AI comprehensive summary
â”‚   â”‚   â”œâ”€â”€ CONTEXT.md        # Quick context
â”‚   â”‚   â””â”€â”€ decisions/        # ADR system
â”‚   â”‚
â””â”€â”€ ğŸ“¸ Session Tracking
    â””â”€â”€ snapshots/            # End-of-day snapshots
```

## Core Pipelines

### 1. Document-to-Plan Pipeline
```
incoming/*.md â†’ analyze.py â†’ run_analyzer.sh â†’ plans/STATUS.md, NEXT_STEPS.md
```

### 2. Focus Generation Pipeline
```
NEXT_STEPS.md â†’ extract_next_steps.sh â†’ FOCUS_LIST.md
```

### 3. AI Memory Pipeline
```
plans/* + research/* â†’ ai_memory_refresh.sh â†’ memory/MEMORY.md, CONTEXT.md
```

### 4. Research Workflow (HITL)
```
ask â†’ research.sh â†’ findings â†’ check â†’ [yes/no] â†’ approved â†’ plans/
```

### 5. Session Management
```
done â†’ eod.sh â†’ snapshot â†’ git commit/tag/push
```

### 6. Analytics Pipeline
```
snapshots/*.txt + git log â†’ analytics.py â†’ productivity metrics
```

## Component Architecture

### Makefile - Command Orchestration
Central command dispatch with 40+ commands organized by function:
- Core workflow: start, fix, work, done
- Analysis: analyze, epics, risks, ideas
- Memory: memory, context, refresh
- Research: ask, check, yes, no, end
- Tools: templates, extract, setup

### Pluggable Analyzers
Base class system for document analysis:
- `base_analyzer.py` - Abstract interface
- `markdown_analyzer.py` - Main document processor
- `risk_analyzer.py` - Risk/blocker detection
- Extensible for new formats (PDF, DOCX, etc.)

### Memory System
AI-powered context management:
- Comprehensive summaries of all project state
- Quick context for immediate reference
- Decision tracking via ADR system
- Git-integrated session history

### Resilience Features
- Safe git operations (handles no-HEAD state)
- Graceful degradation when tools missing
- Color-coded help system
- Pre-commit hook integration

## Data Flow

1. **Input**: Documents placed in `workspace/incoming/`
2. **Processing**: Analyzers extract structure, tasks, risks
3. **Planning**: Generated plans in `workspace/plans/`
4. **Memory**: AI creates comprehensive summaries
5. **Action**: Focus list drives daily work
6. **Tracking**: Sessions captured in snapshots
7. **Evolution**: Git tracks all changes

## Design Principles

- **Document-Centric**: All project state derives from documents
- **Git-Native**: Leverages git for versioning and collaboration
- **Pluggable**: Analyzers and tools can be extended
- **Offline-First**: Works without internet/cloud dependencies
- **Human-Controlled**: AI suggests, humans decide
- **Progressive**: Start simple, add complexity as needed

## Integration Points

- **Git**: Version control, remote collaboration
- **GitHub**: Repository hosting, CI/CD, issues
- **Pre-commit**: Code quality gates
- **Python**: Analysis and AI processing
- **Bash**: System automation and workflow
- **Make**: Command orchestration